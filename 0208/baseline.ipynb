{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 가사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics1 = pd.read_csv(\"./dataset/label_result_song_short.csv\")\n",
    "lyrics2 = pd.read_csv(\"./dataset/translated_lyrics.csv\")\n",
    "\n",
    "lyrics = lyrics2.merge(lyrics1, on=[\"index\", \"id\", \"title\", \"singer\", \"genres\", \"lyrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 소설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_final = pd.read_csv('./dataset/novel_final.csv')\n",
    "data = novel_final.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 가사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 카테고리\n",
    "emotions = ['상처', '불안', '기쁨', '슬픔', '분노', '당황']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 id에 대해 sentiment_label의 빈도를 계산하여, 가장 많이 나온 2개의 감정을 새로운 칼럼으로 추가\n",
    "\n",
    "def get_top_two_sentiments(sentiments):\n",
    "    sentiment_counts = sentiments.value_counts()\n",
    "    # 가장 많은 2개 감정을 반환\n",
    "    top_two = sentiment_counts.head(2).index.tolist()\n",
    "    # 2개 미만일 경우 빈 값 처리\n",
    "    return top_two + [None] * (2 - len(top_two))\n",
    "\n",
    "# groupby와 agg를 활용해 변환\n",
    "lyrics_final = lyrics.groupby(\"id\").agg({\n",
    "    \"title\": \"first\",   # 첫 번째 값 유지\n",
    "    \"singer\": \"first\",  # 첫 번째 값 유지\n",
    "    \"genres\": \"first\",  # 첫 번째 값 유지\n",
    "    \"lyrics\": \"first\",  # 첫 번째 값 유지\n",
    "    \"translated_lyrics\": list,  # 리스트로 묶음\n",
    "    \"sentiment_label\": lambda x: get_top_two_sentiments(x)  # 빈도가 높은 2개의 감정 추출\n",
    "}).reset_index()\n",
    "\n",
    "# sentiment_label에서 두 개의 감정을 각각의 칼럼으로 분리\n",
    "lyrics_final[['top_sentiment', 'second_sentiment']] = pd.DataFrame(lyrics_final['sentiment_label'].tolist(), index=lyrics_final.index)\n",
    "\n",
    "# 불필요한 sentiment_label 열 삭제\n",
    "lyrics_final = lyrics_final.drop(columns=[\"sentiment_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>singer</th>\n",
       "      <th>genres</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>translated_lyrics</th>\n",
       "      <th>top_sentiment</th>\n",
       "      <th>second_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>418168</td>\n",
       "      <td>희재</td>\n",
       "      <td>성시경</td>\n",
       "      <td>발라드, 국내영화</td>\n",
       "      <td>햇살은 우릴 위해 내리고</td>\n",
       "      <td>[햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418598</td>\n",
       "      <td>친구라도 될 걸 그랬어</td>\n",
       "      <td>거미 (GUMMY)</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>벌써 넌 내가 편하니</td>\n",
       "      <td>[벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...</td>\n",
       "      <td>불안</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711626</td>\n",
       "      <td>살다가</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>발라드</td>\n",
       "      <td>살아도 사는 게 아니래</td>\n",
       "      <td>[살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500196</td>\n",
       "      <td>내사람</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>내 가슴속에 사는 사람 내가 그토록 아끼는 사람</td>\n",
       "      <td>[내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854856</td>\n",
       "      <td>라라라</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>발라드</td>\n",
       "      <td>그대는 참 아름다워요</td>\n",
       "      <td>[그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         title      singer     genres                       lyrics  \\\n",
       "0   418168            희재         성시경  발라드, 국내영화               햇살은 우릴 위해 내리고    \n",
       "1   418598  친구라도 될 걸 그랬어  거미 (GUMMY)   R&B/Soul                  벌써 넌 내가 편하니   \n",
       "2   711626           살다가      SG 워너비        발라드                 살아도 사는 게 아니래   \n",
       "3  1500196           내사람      SG 워너비   R&B/Soul  내 가슴속에 사는 사람 내가 그토록 아끼는 사람    \n",
       "4  1854856           라라라      SG 워너비        발라드                  그대는 참 아름다워요   \n",
       "\n",
       "                                   translated_lyrics top_sentiment  \\\n",
       "0  [햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...            슬픔   \n",
       "1  [벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...            불안   \n",
       "2  [살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...            슬픔   \n",
       "3  [내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...            기쁨   \n",
       "4  [그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...            기쁨   \n",
       "\n",
       "  second_sentiment  \n",
       "0               기쁨  \n",
       "1               슬픔  \n",
       "2               불안  \n",
       "3               불안  \n",
       "4               슬픔  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(emotions)\n",
    "\n",
    "lyrics_final['감정1_encoded'] = le.transform(lyrics_final['top_sentiment'])\n",
    "lyrics_final['감정2_encoded'] = le.transform(lyrics_final['second_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 소설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>top_sentiment</th>\n",
       "      <th>second_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>['01범보다 무서운 곶감', '화자를 처음 만나 이야기를 들으러 왔다고 하자 서슴...</td>\n",
       "      <td>분노</td>\n",
       "      <td>당황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>['&lt;봄꿩은 제 울음에 저 죽는다&gt;', '그 말과 같아서 사램이 잘못 되머넌 하는 ...</td>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>['그래 그 여자가 쪄서 쌀얼 쪄서 밥얼 했어.', '“잡수라.”구.', '그래 한...</td>\n",
       "      <td>상처</td>\n",
       "      <td>당황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>['그랴. 그래 우리 인제 사춘 찾어간다는 얘기를 족~ 갈쳐중개,', '“그러시냐구...</td>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>['나와서 인제 그 집 먼지 인저 그, 그, 뭐여 면사무소 있는 디 나와서 인제, ...</td>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      title                                               text  \\\n",
       "0           0  이야기꾼 구연설화  ['01범보다 무서운 곶감', '화자를 처음 만나 이야기를 들으러 왔다고 하자 서슴...   \n",
       "1           1  이야기꾼 구연설화  ['<봄꿩은 제 울음에 저 죽는다>', '그 말과 같아서 사램이 잘못 되머넌 하는 ...   \n",
       "2           2  이야기꾼 구연설화  ['그래 그 여자가 쪄서 쌀얼 쪄서 밥얼 했어.', '“잡수라.”구.', '그래 한...   \n",
       "3           3  이야기꾼 구연설화  ['그랴. 그래 우리 인제 사춘 찾어간다는 얘기를 족~ 갈쳐중개,', '“그러시냐구...   \n",
       "4           4  이야기꾼 구연설화  ['나와서 인제 그 집 먼지 인저 그, 그, 뭐여 면사무소 있는 디 나와서 인제, ...   \n",
       "\n",
       "  top_sentiment second_sentiment  \n",
       "0            분노               당황  \n",
       "1            상처               분노  \n",
       "2            상처               당황  \n",
       "3            상처               분노  \n",
       "4            상처               분노  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_sentiment</th>\n",
       "      <th>second_sentiment</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>불안</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>3 | 5 | 18부 영우는 차창을 바라보았다. 찬바람이 여러 겹씩 두껍게 옷을 입...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>불안</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>3 | 0 | 의문과 실망으로 착잡한 박전전과는 달리 서천양은 여유만만이었다. 입이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>불안</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>3 | 5 | 규하가 춘봉을 향해 뚜벅뚜벅 걸어왔다. 춘봉의 동공이 점점 커지고 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>기쁨</td>\n",
       "      <td>불안</td>\n",
       "      <td>0 | 3 | 엘프답지 않은 쌍스러운 말이었지만 일반적인 엘프와는 달리 전사의 기운...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>불안</td>\n",
       "      <td>당황</td>\n",
       "      <td>3 | 1 | \"사실 우연이란 놈은 무서운 장난꾼입니다. 저는 이 장난꾼에게 한번 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_sentiment second_sentiment  \\\n",
       "2400            불안               슬픔   \n",
       "6877            불안               기쁨   \n",
       "5369            불안               슬픔   \n",
       "4268            기쁨               불안   \n",
       "1326            불안               당황   \n",
       "\n",
       "                                             input_text  \n",
       "2400  3 | 5 | 18부 영우는 차창을 바라보았다. 찬바람이 여러 겹씩 두껍게 옷을 입...  \n",
       "6877  3 | 0 | 의문과 실망으로 착잡한 박전전과는 달리 서천양은 여유만만이었다. 입이...  \n",
       "5369  3 | 5 | 규하가 춘봉을 향해 뚜벅뚜벅 걸어왔다. 춘봉의 동공이 점점 커지고 있...  \n",
       "4268  0 | 3 | 엘프답지 않은 쌍스러운 말이었지만 일반적인 엘프와는 달리 전사의 기운...  \n",
       "1326  3 | 1 | \"사실 우연이란 놈은 무서운 장난꾼입니다. 저는 이 장난꾼에게 한번 ...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelEncoder 초기화\n",
    "le = LabelEncoder()\n",
    "le.fit(emotions)\n",
    "\n",
    "# 감정1과 감정2를 숫자로 변환\n",
    "data['감정1_encoded'] = le.transform(data['top_sentiment'])\n",
    "data['감정2_encoded'] = le.transform(data['second_sentiment'])\n",
    "\n",
    "# 수치형 감정1, 감정2와 텍스트 결합\n",
    "data['input_text'] = data['감정1_encoded'].astype(str) + \" | \" + data['감정2_encoded'].astype(str) + \" | \" + data['text']\n",
    "\n",
    "# 불필요한 문자 제거\n",
    "data['input_text'] = data['input_text'].str.replace(r\"[\\[\\],']\", \"\", regex=True)\n",
    "\n",
    "data[['top_sentiment', 'second_sentiment', 'input_text']].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기쁨: 0\n",
      "당황: 1\n",
      "분노: 2\n",
      "불안: 3\n",
      "상처: 4\n",
      "슬픔: 5\n"
     ]
    }
   ],
   "source": [
    "# 감정별 숫자 매핑 출력\n",
    "for emotion, label in zip(le.classes_, le.transform(le.classes_)):\n",
    "    print(f\"{emotion}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class NovelsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, text_column=\"input_text\", max_length=128):\n",
    "        self.data = data.reset_index(drop=True)  # 인덱스 리셋 (중복 방지)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_column = text_column\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, self.text_column] # input_text 가져오기\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        # labels 생성 (input_ids 복사 및 패딩 토큰을 -100으로 설정)\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "# KOGPT2 모델과 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')\n",
    "\n",
    "# 모델 초기화\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.bos_token_id = tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NovelsDataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_novels, eval_novels = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = NovelsDataset(train_novels, tokenizer)\n",
    "eval_dataset = NovelsDataset(eval_novels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer에 데이터셋 전달\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,  # 검증 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([ 9085,   739,   466,  9020,   739,   466, 10063,  7584,  9391, 21182,\n",
      "        12311, 35142, 13875,  9317, 16299, 13568, 18017,  9717, 17631, 11247,\n",
      "        15972,  7621,  7422,  8263,   739,     5, 23775, 47711, 10063,  7669,\n",
      "         7445, 11001, 22580, 26309,  7185,  9135, 13115,   406,   377,  9546,\n",
      "         7407, 32552,  9069,  7560,  8159, 22301,  8024,  9274,  7407,  7543,\n",
      "         8146, 16626, 13872, 10063,  8762, 10072,  9215, 18282,  9215,  9878,\n",
      "        13969,  9261, 19023,  9174,  9179,  9432, 12004,  9825, 12024,  7281,\n",
      "         6883,  9173, 13444, 32987,   377, 10063,  8052,  9055,  8694, 15509,\n",
      "          376,  9174,  9179,  9432, 17104,  8744,  7055,  7652,  6919,  7514,\n",
      "          389, 46651,  6824, 12222, 21832,  9122,  7991,   406, 25758,  9720,\n",
      "         6958,  9237, 22882,   406, 16518, 15518, 39717,  9193, 22882,   406,\n",
      "          377,  9546,  7407, 19902, 18191,  6824, 32738,  8006,  9042,  9313,\n",
      "        44083, 14870,  9064,  7472,  7326,  9016, 10063, 17653])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Labels: tensor([ 9085,   739,   466,  9020,   739,   466, 10063,  7584,  9391, 21182,\n",
      "        12311, 35142, 13875,  9317, 16299, 13568, 18017,  9717, 17631, 11247,\n",
      "        15972,  7621,  7422,  8263,   739,     5, 23775, 47711, 10063,  7669,\n",
      "         7445, 11001, 22580, 26309,  7185,  9135, 13115,   406,   377,  9546,\n",
      "         7407, 32552,  9069,  7560,  8159, 22301,  8024,  9274,  7407,  7543,\n",
      "         8146, 16626, 13872, 10063,  8762, 10072,  9215, 18282,  9215,  9878,\n",
      "        13969,  9261, 19023,  9174,  9179,  9432, 12004,  9825, 12024,  7281,\n",
      "         6883,  9173, 13444, 32987,   377, 10063,  8052,  9055,  8694, 15509,\n",
      "          376,  9174,  9179,  9432, 17104,  8744,  7055,  7652,  6919,  7514,\n",
      "          389, 46651,  6824, 12222, 21832,  9122,  7991,   406, 25758,  9720,\n",
      "         6958,  9237, 22882,   406, 16518, 15518, 39717,  9193, 22882,   406,\n",
      "          377,  9546,  7407, 19902, 18191,  6824, 32738,  8006,  9042,  9313,\n",
      "        44083, 14870,  9064,  7472,  7326,  9016, 10063, 17653])\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(\"Input IDs:\", sample['input_ids'])\n",
    "print(\"Attention Mask:\", sample['attention_mask'])\n",
    "print(\"Labels:\", sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5045' max='5045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5045/5045 21:37, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.206400</td>\n",
       "      <td>4.094640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.811800</td>\n",
       "      <td>4.055212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.500900</td>\n",
       "      <td>4.078753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.142436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5045, training_loss=3.507166806911926, metrics={'train_runtime': 1298.1008, 'train_samples_per_second': 31.099, 'train_steps_per_second': 3.886, 'total_flos': 2634868850688000.0, 'train_loss': 3.507166806911926, 'epoch': 4.995788952192222})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# 이야기 생성 함수\n",
    "def generate_story(lyrics_input):\n",
    "    # 입력 토큰화\n",
    "    input_ids = tokenizer.encode(lyrics_input, return_tensors='pt').to(device)\n",
    "\n",
    "    # 출력 생성\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_new_tokens=150, # 새로 생성할 토큰의 개수를 제한\n",
    "        num_return_sequences=1, \n",
    "        temperature=0.8, \n",
    "        top_k=50, \n",
    "        top_p=0.9, \n",
    "        repetition_penalty=1.2, \n",
    "        do_sample=True  # 샘플링 활성화\n",
    "    )\n",
    "\n",
    "    # 입력 길이 추적\n",
    "    input_length = input_ids.shape[1]\n",
    "\n",
    "    # 생성된 토큰 중 입력 토큰 이후의 부분만 디코딩\n",
    "    generated_tokens = output[0][input_length:]\n",
    "    generated_story = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return generated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Show\n"
     ]
    }
   ],
   "source": [
    "i = 732\n",
    "print(lyrics_final[\"title\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 | 0 | 이젠 혼자가 아닐 무대 너무나 감격스러워 끝없는 가능성 중에 날 골라줘서 고마워 나와 맞이하는 미래가 위태로울지도 몰라 하지만 눈물 가득한 감동이 있을지도 몰라 그래도 내 손 놓지 않겠다면 만약 그래서 그러면 봅시다 밖으로 나가  환영합니다. 옆으로 그리고 보여주는 것 Oh 이것만큼은 맹세할게 내 전부를 다 바칠게 네 눈빛 흔들리지 않게 널 바라보며 서 있을게 알아 너의 결정이  쉽지 않았을 거야 후회 없게 하는 건  이제 나의 몫이야 끝까지 같이 함께 가겠다면 만약 그래서 그러면 봅시다 밖으로 나가 환영합니다. 옆으로 그리고 보여주는 것 Oh 이것만큼은 맹세할게 내 전부를 다 바칠게 네 눈빛 흔들리지 않게 널 바라보며 서 있을게 막이 내릴 그날에도 그때도 네 손 꼭 잡은 채 너라서 행복했다고 서로가 말할 수 있도록  이것만큼은 맹세할게 내 전부를 다 바칠게 네 눈빛 흔들리지 않게 널 바라보며 서 있을게 Oh Oh\n"
     ]
    }
   ],
   "source": [
    "lyrics = \" \".join(lyrics_final[\"translated_lyrics\"][i])\n",
    "\n",
    "prompt = lyrics_final['감정1_encoded'][i].astype(str) + \" | \" + lyrics_final['감정2_encoded'][i].astype(str) + \" | \" + lyrics\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 이야기: ! \"와아~-씨아. 안녕하하셨어요?\" 나 오랜만에 좋은 아침인데 반갑습니다 반가운 마음에 드는 얼굴로 인사합니다 우린다. 어제 저녁에 잘 먹고 인사 나누었는데 너무 좋네. 축하해 우리 윤정이가 간만에 하이라며 인사하러 갑니가 먼저 가자꾸나~^. 흐흐아 정혜리 오후의 두근덕한 기분 좋아하네 미팅으로 반갑에 대한 인사를 받고 집으로 가시고 정숙인께 우리 집에 들러 앉으니까 하여 차 한잔하게 저녁 먹자.... \"윤아~오케 하기로 합심해서 인사해주세.\" \"와하네. 아이고우~~ ᆞ0_\n"
     ]
    }
   ],
   "source": [
    "# 가사로 이야기 생성\n",
    "generated_story = generate_story(prompt)\n",
    "print(\"생성된 이야기:\", generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 이야기: 인지 이젠데 왜 내가 좋아하는지 그래 속상하기만 말예 퇴근거리는 게 참으론 정말이지 남이 나를 버리고 지금이 딱히 한숨 쉬었는지 알면서.... 이러면 금방엔 숨소리 질러 가며 소리 죽여 버릇한 기분이 좋아서 그냥 그러는 거냐? 이제 더러운 세상 물끄떡하고 예사로운 걸어서 그런 건가 못해~ 하고 사는데. 그만 이렇게 예쁜 척하는 소리가 나랑말루 오죽 나래 그래 가지 않고 그저 눈 감고 삐딱다리 놓으면 살그렁거니 이마에 이어두 못 하게 할까 봐놓고 사는 저러다 말고 다리 뻗고 가만히 들여다보면 예뻐한다ᆞ오래야 제자리 앉으며 맘\n"
     ]
    }
   ],
   "source": [
    "# 가사로 이야기 생성\n",
    "# lyrics_input = \"어쩌다 고작 그 마음도 못 참고 멍청하게 다 던졌는지 뭔가 들켜 버린 것 같아 표정을 보니 말이야 나도 티가 나버린 고백에 얼마나 놀랐는지 몰라 매일 치는 장난에도 두근댔고 오늘도 몇 번이고 떨렸지만 약속했어 날 안아줘 좀 알아줘 이건 꿈에서만 하기야 무심코 던진 니 말에 하루 종일 설레어 간직했다 아무도 못 보게 일기장에 적어 단단히 잠궜었는데 어쩌다 고작 그 마음도 못 참고 멍청하게 다 던졌는지 꾹꾹 참고 또 꼭꼭 숨겨서 이제까지 잘해 왔잖아 그러다 고작 울음도 못 참고 괜찮다 말하며 두 눈은 퉁퉁 붓고 코맹맹이가 되어도 난 내일은 맑음 예전처럼 옆에서 밥 먹어도 우연히 눈이 살짝 마주쳐도 걱정 마 날 안아줘 아니 사랑해줘 이건 꿈에서만 하니까 무심코 던진 니 말에 하루 종일 설레어 간직했다 아무도 못 보게 꼬깃꼬깃 구겨 씹어 다 삼켰었는데 어쩌다 고작 그 마음도 못 참고 멍청하게 다 던졌는지 꾹꾹 참고 또 꼭꼭 숨겨서 이제까지 잘 해 왔잖아 그러다 고작 울음도 못 참고 괜찮다 말하며 두 눈은 퉁퉁 붓고 코맹맹이가 되어도 난 사실 나 아주 오래 울 것 같아 고작 친구도 못 되니까 툭툭 털고 활짝 웃을 만큼 나는 그리 강하지가 않아 그러다 고작 사랑이 뭐라고 괜찮다 말하는 날까지 꾹꾹 참고 또 일기나 쓰고 있어 나 내 이름 맑음\"\n",
    "# generated_story = generate_story(lyrics_input, tag1=\"2\", tag2=\"2\")\n",
    "# print(\"생성된 이야기:\", generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
