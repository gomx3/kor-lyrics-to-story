{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 가사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics1 = pd.read_csv(\"./dataset/label_result_song_short.csv\")\n",
    "lyrics2 = pd.read_csv(\"./dataset/translated_lyrics.csv\")\n",
    "\n",
    "lyrics = lyrics2.merge(lyrics1, on=[\"index\", \"id\", \"title\", \"singer\", \"genres\", \"lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>singer</th>\n",
       "      <th>genres</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>translated_lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37140709</td>\n",
       "      <td>첫 만남은 계획대로 되지 않아</td>\n",
       "      <td>TWS (투어스)</td>\n",
       "      <td>댄스</td>\n",
       "      <td>Ay ay ay ay ay</td>\n",
       "      <td>Ay ay ay ay ay</td>\n",
       "      <td>2</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37140709</td>\n",
       "      <td>첫 만남은 계획대로 되지 않아</td>\n",
       "      <td>TWS (투어스)</td>\n",
       "      <td>댄스</td>\n",
       "      <td>거울 속에 내 표정 봐 봐</td>\n",
       "      <td>거울 속에 내 표정 봐 봐</td>\n",
       "      <td>5</td>\n",
       "      <td>당황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37140709</td>\n",
       "      <td>첫 만남은 계획대로 되지 않아</td>\n",
       "      <td>TWS (투어스)</td>\n",
       "      <td>댄스</td>\n",
       "      <td>느낌 So good 기다려온 D-day</td>\n",
       "      <td>느낌 그래서 좋아요. 기다려온 D-하루</td>\n",
       "      <td>0</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37140709</td>\n",
       "      <td>첫 만남은 계획대로 되지 않아</td>\n",
       "      <td>TWS (투어스)</td>\n",
       "      <td>댄스</td>\n",
       "      <td>연습했던 손든 인사도 그대로 하면 돼</td>\n",
       "      <td>연습했던 손든 인사도 그대로 하면 돼</td>\n",
       "      <td>0</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37140709</td>\n",
       "      <td>첫 만남은 계획대로 되지 않아</td>\n",
       "      <td>TWS (투어스)</td>\n",
       "      <td>댄스</td>\n",
       "      <td>Hairstyle check하고 한 번 Turn around</td>\n",
       "      <td>머리스타일 확인하고 한 번 회전 주변</td>\n",
       "      <td>2</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id             title     singer genres  \\\n",
       "0      1  37140709  첫 만남은 계획대로 되지 않아  TWS (투어스)     댄스   \n",
       "1      2  37140709  첫 만남은 계획대로 되지 않아  TWS (투어스)     댄스   \n",
       "2      3  37140709  첫 만남은 계획대로 되지 않아  TWS (투어스)     댄스   \n",
       "3      4  37140709  첫 만남은 계획대로 되지 않아  TWS (투어스)     댄스   \n",
       "4      5  37140709  첫 만남은 계획대로 되지 않아  TWS (투어스)     댄스   \n",
       "\n",
       "                              lyrics      translated_lyrics  sentiment  \\\n",
       "0                     Ay ay ay ay ay         Ay ay ay ay ay          2   \n",
       "1                     거울 속에 내 표정 봐 봐         거울 속에 내 표정 봐 봐          5   \n",
       "2              느낌 So good 기다려온 D-day  느낌 그래서 좋아요. 기다려온 D-하루          0   \n",
       "3               연습했던 손든 인사도 그대로 하면 돼   연습했던 손든 인사도 그대로 하면 돼          0   \n",
       "4  Hairstyle check하고 한 번 Turn around   머리스타일 확인하고 한 번 회전 주변          2   \n",
       "\n",
       "  sentiment_label  \n",
       "0              분노  \n",
       "1              당황  \n",
       "2              기쁨  \n",
       "3              기쁨  \n",
       "4              분노  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 소설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21564\\3047535869.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnovel_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./dataset/classified_novel1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnovel_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "novel_final = pd.read_csv('./dataset/classified_novel1.csv')\n",
    "data = novel_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(n=50000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>file_id</th>\n",
       "      <th>title</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347937</td>\n",
       "      <td>WARW1900000524</td>\n",
       "      <td>남도빨치산 6</td>\n",
       "      <td>WARW1900000524.1.2310</td>\n",
       "      <td>\"손들고 나왓!\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570921</td>\n",
       "      <td>WARW1900000808</td>\n",
       "      <td>제갈공명 2-하늘로 치솟아 뜻을 펼치다</td>\n",
       "      <td>WARW1900000808.1.1898</td>\n",
       "      <td>\"그 점은 이 양이 생각해둔 바 있으니 과히 염려하지 마십시오. 틀림없이 연환계를 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257278</td>\n",
       "      <td>WARW1900000461</td>\n",
       "      <td>890만번 주사위 던지기</td>\n",
       "      <td>WARW1900000461.1.504</td>\n",
       "      <td>\"102…103…104…….\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>702456</td>\n",
       "      <td>WARW1900001046</td>\n",
       "      <td>경찰청장 박전전 3</td>\n",
       "      <td>WARW1900001046.1.841</td>\n",
       "      <td>그 두 가지 사실이 무엇을 의미하는가?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228104</td>\n",
       "      <td>WARW1900000425</td>\n",
       "      <td>퇴원</td>\n",
       "      <td>WARW1900000425.1.1765</td>\n",
       "      <td>\"어서 그냥 쇠새끼나 쫓아가보거라. 꼴짐은 내가 거둬 지고 가마.\"</td>\n",
       "      <td>2.0</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1         file_id                  title           paragraph_id  \\\n",
       "0   347937  WARW1900000524                남도빨치산 6  WARW1900000524.1.2310   \n",
       "1   570921  WARW1900000808  제갈공명 2-하늘로 치솟아 뜻을 펼치다  WARW1900000808.1.1898   \n",
       "2   257278  WARW1900000461          890만번 주사위 던지기   WARW1900000461.1.504   \n",
       "3   702456  WARW1900001046             경찰청장 박전전 3   WARW1900001046.1.841   \n",
       "4   228104  WARW1900000425                     퇴원  WARW1900000425.1.1765   \n",
       "\n",
       "                                                text  labels sentiment  \n",
       "0                                          \"손들고 나왓!\"     0.0        기쁨  \n",
       "1  \"그 점은 이 양이 생각해둔 바 있으니 과히 염려하지 마십시오. 틀림없이 연환계를 ...     0.0        기쁨  \n",
       "2                                   \"102…103…104…….\"     4.0        불안  \n",
       "3                              그 두 가지 사실이 무엇을 의미하는가?     1.0        슬픔  \n",
       "4              \"어서 그냥 쇠새끼나 쫓아가보거라. 꼴짐은 내가 거둬 지고 가마.\"     2.0        분노  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수: 0\n",
      "None 포함 여부: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN 개수:\", data['text'].isna().sum())  # NaN 개수 확인\n",
    "print(\"None 포함 여부:\", data['text'].isnull().sum())  # None 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수: 0\n",
      "None 포함 여부: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN 개수:\", data['text'].isna().sum())  # NaN 개수 확인\n",
    "print(\"None 포함 여부:\", data['text'].isnull().sum())  # None 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class NovelsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, text_column=\"input_text\", max_length=128):\n",
    "        self.data = data.reset_index(drop=True)  # 인덱스 리셋 (중복 방지)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_column = text_column\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, self.text_column] # input_text 가져오기\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        # labels 생성 (input_ids 복사 및 패딩 토큰을 -100으로 설정)\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "# KOGPT2 모델과 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')\n",
    "\n",
    "# 모델 초기화\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.bos_token_id = tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NovelsDataset(data, tokenizer, text_column=\"text\")\n",
    "dataloader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=5e-5,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_novels, eval_novels = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = NovelsDataset(train_novels, tokenizer, text_column=\"text\")\n",
    "eval_dataset = NovelsDataset(eval_novels, tokenizer, text_column=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_novels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer에 데이터셋 전달\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,  # 검증 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([10063, 18331,  7177,  6995,  7162,  9298,  9436,  9126, 16148,  9536,\n",
      "         9049, 11607, 24699, 40734, 23916, 11888, 11768,  9199, 13177,  8702,\n",
      "         8062, 23775,   406,   377,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Labels: tensor([10063, 18331,  7177,  6995,  7162,  9298,  9436,  9126, 16148,  9536,\n",
      "         9049, 11607, 24699, 40734, 23916, 11888, 11768,  9199, 13177,  8702,\n",
      "         8062, 23775,   406,   377,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(\"Input IDs:\", sample['input_ids'])\n",
    "print(\"Attention Mask:\", sample['attention_mask'])\n",
    "print(\"Labels:\", sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14060' max='14060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14060/14060 1:27:25, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.530700</td>\n",
       "      <td>4.555839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.071900</td>\n",
       "      <td>4.492127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.581800</td>\n",
       "      <td>4.504992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.946600</td>\n",
       "      <td>4.603178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14060, training_loss=3.678667727778341, metrics={'train_runtime': 5246.2433, 'train_samples_per_second': 42.888, 'train_steps_per_second': 2.68, 'total_flos': 1.4692973543424e+16, 'train_loss': 3.678667727778341, 'epoch': 4.9984})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이야기 생성 함수\n",
    "def generate_story(lyrics_input):\n",
    "    # 입력 토큰화\n",
    "    input_ids = tokenizer.encode(lyrics_input, return_tensors='pt').to(device)\n",
    "\n",
    "    # 출력 생성\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_new_tokens=150, # 새로 생성할 토큰의 개수를 제한\n",
    "        num_return_sequences=1, \n",
    "        temperature=0.8, \n",
    "        top_k=50, \n",
    "        top_p=0.9, \n",
    "        repetition_penalty=1.2, \n",
    "        do_sample=True  # 샘플링 활성화\n",
    "    )\n",
    "\n",
    "    # 입력 길이 추적\n",
    "    input_length = input_ids.shape[1]\n",
    "\n",
    "    # 생성된 토큰 중 입력 토큰 이후의 부분만 디코딩\n",
    "    generated_tokens = output[0][input_length:]\n",
    "    generated_story = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return generated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics1 = pd.read_csv(\"./dataset/label_result_song_short.csv\")\n",
    "lyrics2 = pd.read_csv(\"./dataset/translated_lyrics.csv\")\n",
    "\n",
    "lyrics = lyrics2.merge(lyrics1, on=[\"index\", \"id\", \"title\", \"singer\", \"genres\", \"lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby와 agg를 활용해 변환\n",
    "lyrics_input = lyrics.groupby(\"id\").agg({\n",
    "    \"title\": \"first\",   # 첫 번째 값 유지\n",
    "    \"singer\": \"first\",  # 첫 번째 값 유지\n",
    "    \"genres\": \"first\",  # 첫 번째 값 유지\n",
    "    \"lyrics\": list,  # 첫 번째 값 유지\n",
    "    \"translated_lyrics\": list,  # 리스트로 묶음\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>singer</th>\n",
       "      <th>genres</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>translated_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>418168</td>\n",
       "      <td>희재</td>\n",
       "      <td>성시경</td>\n",
       "      <td>발라드, 국내영화</td>\n",
       "      <td>[햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...</td>\n",
       "      <td>[햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418598</td>\n",
       "      <td>친구라도 될 걸 그랬어</td>\n",
       "      <td>거미 (GUMMY)</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>[벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...</td>\n",
       "      <td>[벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711626</td>\n",
       "      <td>살다가</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>발라드</td>\n",
       "      <td>[살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...</td>\n",
       "      <td>[살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500196</td>\n",
       "      <td>내사람</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>[내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...</td>\n",
       "      <td>[내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854856</td>\n",
       "      <td>라라라</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>발라드</td>\n",
       "      <td>[그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...</td>\n",
       "      <td>[그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         title      singer     genres  \\\n",
       "0   418168            희재         성시경  발라드, 국내영화   \n",
       "1   418598  친구라도 될 걸 그랬어  거미 (GUMMY)   R&B/Soul   \n",
       "2   711626           살다가      SG 워너비        발라드   \n",
       "3  1500196           내사람      SG 워너비   R&B/Soul   \n",
       "4  1854856           라라라      SG 워너비        발라드   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  [햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...   \n",
       "1  [벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...   \n",
       "2  [살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...   \n",
       "3  [내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...   \n",
       "4  [그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...   \n",
       "\n",
       "                                   translated_lyrics  \n",
       "0  [햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...  \n",
       "1  [벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...  \n",
       "2  [살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...  \n",
       "3  [내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...  \n",
       "4  [그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내 이름 맑음\n"
     ]
    }
   ],
   "source": [
    "i = 751\n",
    "print(lyrics_input[\"title\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어쩌다 고작 그 마음도 못 참고 멍청하게 다 던졌는지 뭔가 들켜 버린 것 같아 표정을 보니 말이야 나도 티가 나버린 고백에 얼마나 놀랐는지 몰라 매일 치는 장난에도 두근댔고 오늘도 몇 번이고 떨렸지만 약속했어 날 안아줘 좀 알아줘 이건 꿈에서만 하기야  무심코 던진 니 말에 하루 종일 설레어 간직했다 아무도 못 보게 일기장에 적어 단단히 잠궜었는데 어쩌다 고작 그 마음도 못 참고 멍청하게 다 던졌는지 꾹꾹 참고 또 꼭꼭 숨겨서 이제까지 잘해 왔잖아 그러다 고작 울음도 못 참고 괜찮다 말하며 두 눈은 퉁퉁 붓고 코맹맹이가 되어도 난 내일은 맑음 예전처럼 옆에서 밥 먹어도 우연히 눈이 살짝 마주쳐도 걱정 마 날 안아줘 아니 사랑해줘 이건 꿈에서만 하니까 무심코 던진 니 말에 하루 종일 설레어 간직했다 아무도 못 보게 꼬깃꼬깃 구겨 씹어 다 삼켰었는데 어쩌다 고작 그 마음도 못 참고 멍청하게 다 던졌는지 꾹꾹 참고 또 꼭꼭 숨겨서 이제까지 잘 해 왔잖아 그러다 고작 울음도 못 참고 괜찮다 말하며 두 눈은 퉁퉁 붓고 코맹맹이가 되어도 난 사실 나  아주 오래 울 것 같아 고작 친구도 못 되니까 툭툭 털고 활짝 웃을 만큼 나는 그리 강하지가 않아 그러다 고작 사랑이 뭐라고 괜찮다 말하는 날까지  꾹꾹 참고 또 일기나 쓰고 있어 나 내 이름 맑음\n"
     ]
    }
   ],
   "source": [
    "prompt = \" \".join(lyrics_input[\"translated_lyrics\"][i])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[229], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 가사로 이야기 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m generated_story \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_story\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m생성된 이야기:\u001b[39m\u001b[38;5;124m\"\u001b[39m, generated_story)\n",
      "Cell \u001b[1;32mIn[222], line 4\u001b[0m, in \u001b[0;36mgenerate_story\u001b[1;34m(lyrics_input)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_story\u001b[39m(lyrics_input):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 입력 토큰화\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlyrics_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 출력 생성\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      8\u001b[0m         input_ids, \n\u001b[0;32m      9\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, \u001b[38;5;66;03m# 새로 생성할 토큰의 개수를 제한\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# 샘플링 활성화\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 가사로 이야기 생성\n",
    "generated_story = generate_story(prompt)\n",
    "print(\"생성된 이야기:\", generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 이야기들을 저장할 리스트\n",
    "generated_stories = []\n",
    "\n",
    "# 651부터 750까지 반복하여 가사로 이야기 생성\n",
    "for i in range(651, 751):\n",
    "    # 각 가사 제목과 번역된 가사 추출\n",
    "    title = lyrics_input[\"title\"][i]\n",
    "    prompt = \" \".join(lyrics_input[\"translated_lyrics\"][i])\n",
    "\n",
    "    # 가사로 이야기 생성\n",
    "    generated_story = generate_story(prompt)\n",
    "\n",
    "    # 결과 저장\n",
    "    generated_stories.append({\"title\": title, \"generated_story\": generated_story})\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "df = pd.DataFrame(generated_stories)\n",
    "\n",
    "# CSV로 저장\n",
    "df.to_csv(\"generated_stories_651_750.csv\", index=False)\n",
    "\n",
    "print(\"저장 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 이야기: 인지 이젠데 왜 내가 좋아하는지 그래 속상하기만 말예 퇴근거리는 게 참으론 정말이지 남이 나를 버리고 지금이 딱히 한숨 쉬었는지 알면서.... 이러면 금방엔 숨소리 질러 가며 소리 죽여 버릇한 기분이 좋아서 그냥 그러는 거냐? 이제 더러운 세상 물끄떡하고 예사로운 걸어서 그런 건가 못해~ 하고 사는데. 그만 이렇게 예쁜 척하는 소리가 나랑말루 오죽 나래 그래 가지 않고 그저 눈 감고 삐딱다리 놓으면 살그렁거니 이마에 이어두 못 하게 할까 봐놓고 사는 저러다 말고 다리 뻗고 가만히 들여다보면 예뻐한다ᆞ오래야 제자리 앉으며 맘\n"
     ]
    }
   ],
   "source": [
    "# 가사로 이야기 생성\n",
    "# lyrics_input = \"\"\n",
    "# generated_story = generate_story(lyrics_input, tag1=\"2\", tag2=\"2\")\n",
    "# print(\"생성된 이야기:\", generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
