{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 가사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics1 = pd.read_csv(\"./dataset/label_result_song_short.csv\")\n",
    "lyrics2 = pd.read_csv(\"./dataset/translated_lyrics.csv\")\n",
    "\n",
    "lyrics = lyrics2.merge(lyrics1, on=[\"index\", \"id\", \"title\", \"singer\", \"genres\", \"lyrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 소설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_final = pd.read_csv('./dataset/classified_novel1.csv')\n",
    "data = novel_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885014"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.sample(n=50000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>file_id</th>\n",
       "      <th>title</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>WARW1800000007</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>WARW1800000007.1.1</td>\n",
       "      <td>01범보다 무서운 곶감</td>\n",
       "      <td>4.0</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WARW1800000007</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>WARW1800000007.1.2</td>\n",
       "      <td>화자를 처음 만나 이야기를 들으러 왔다고 하자 서슴없이 꺼낸 첫 이야기이다. 화자로...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WARW1800000007</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>WARW1800000007.1.3</td>\n",
       "      <td>그링깨. 사람이 어거지루는 못 살구. 응? 어거지루 안 되능 거여. 사람이 그링깨 ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WARW1800000007</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>WARW1800000007.1.4</td>\n",
       "      <td>그래 옛날, 그 꼭감이라능 게 말여. 사람이 먹잖야 이케? 먹지마는. 그게 참 무성...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WARW1800000007</td>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>WARW1800000007.1.5</td>\n",
       "      <td>애기가 울어. 옛날에. 그래 할머니가 달갸(달래). 그때 호랭이가, 응? 그 집 문...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1         file_id      title        paragraph_id  \\\n",
       "0        0  WARW1800000007  이야기꾼 구연설화  WARW1800000007.1.1   \n",
       "1        1  WARW1800000007  이야기꾼 구연설화  WARW1800000007.1.2   \n",
       "2        2  WARW1800000007  이야기꾼 구연설화  WARW1800000007.1.3   \n",
       "3        3  WARW1800000007  이야기꾼 구연설화  WARW1800000007.1.4   \n",
       "4        4  WARW1800000007  이야기꾼 구연설화  WARW1800000007.1.5   \n",
       "\n",
       "                                                text  labels sentiment  \n",
       "0                                       01범보다 무서운 곶감     4.0        불안  \n",
       "1  화자를 처음 만나 이야기를 들으러 왔다고 하자 서슴없이 꺼낸 첫 이야기이다. 화자로...     4.0        불안  \n",
       "2  그링깨. 사람이 어거지루는 못 살구. 응? 어거지루 안 되능 거여. 사람이 그링깨 ...     2.0        분노  \n",
       "3  그래 옛날, 그 꼭감이라능 게 말여. 사람이 먹잖야 이케? 먹지마는. 그게 참 무성...     4.0        불안  \n",
       "4  애기가 울어. 옛날에. 그래 할머니가 달갸(달래). 그때 호랭이가, 응? 그 집 문...     1.0        슬픔  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 가사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 카테고리\n",
    "emotions = ['상처', '불안', '기쁨', '슬픔', '분노', '당황']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 id에 대해 sentiment_label의 빈도를 계산하여, 가장 많이 나온 2개의 감정을 새로운 칼럼으로 추가\n",
    "\n",
    "def get_top_two_sentiments(sentiments):\n",
    "    sentiment_counts = sentiments.value_counts()\n",
    "    # 가장 많은 2개 감정을 반환\n",
    "    top_two = sentiment_counts.head(2).index.tolist()\n",
    "    # 2개 미만일 경우 빈 값 처리\n",
    "    return top_two + [None] * (2 - len(top_two))\n",
    "\n",
    "# groupby와 agg를 활용해 변환\n",
    "lyrics_final = lyrics.groupby(\"id\").agg({\n",
    "    \"title\": \"first\",   # 첫 번째 값 유지\n",
    "    \"singer\": \"first\",  # 첫 번째 값 유지\n",
    "    \"genres\": \"first\",  # 첫 번째 값 유지\n",
    "    \"lyrics\": \"first\",  # 첫 번째 값 유지\n",
    "    \"translated_lyrics\": list,  # 리스트로 묶음\n",
    "    \"sentiment_label\": lambda x: get_top_two_sentiments(x)  # 빈도가 높은 2개의 감정 추출\n",
    "}).reset_index()\n",
    "\n",
    "# sentiment_label에서 두 개의 감정을 각각의 칼럼으로 분리\n",
    "lyrics_final[['top_sentiment', 'second_sentiment']] = pd.DataFrame(lyrics_final['sentiment_label'].tolist(), index=lyrics_final.index)\n",
    "\n",
    "# 불필요한 sentiment_label 열 삭제\n",
    "lyrics_final = lyrics_final.drop(columns=[\"sentiment_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>singer</th>\n",
       "      <th>genres</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>translated_lyrics</th>\n",
       "      <th>top_sentiment</th>\n",
       "      <th>second_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>418168</td>\n",
       "      <td>희재</td>\n",
       "      <td>성시경</td>\n",
       "      <td>발라드, 국내영화</td>\n",
       "      <td>햇살은 우릴 위해 내리고</td>\n",
       "      <td>[햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418598</td>\n",
       "      <td>친구라도 될 걸 그랬어</td>\n",
       "      <td>거미 (GUMMY)</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>벌써 넌 내가 편하니</td>\n",
       "      <td>[벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...</td>\n",
       "      <td>불안</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711626</td>\n",
       "      <td>살다가</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>발라드</td>\n",
       "      <td>살아도 사는 게 아니래</td>\n",
       "      <td>[살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500196</td>\n",
       "      <td>내사람</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>내 가슴속에 사는 사람 내가 그토록 아끼는 사람</td>\n",
       "      <td>[내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854856</td>\n",
       "      <td>라라라</td>\n",
       "      <td>SG 워너비</td>\n",
       "      <td>발라드</td>\n",
       "      <td>그대는 참 아름다워요</td>\n",
       "      <td>[그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         title      singer     genres                       lyrics  \\\n",
       "0   418168            희재         성시경  발라드, 국내영화               햇살은 우릴 위해 내리고    \n",
       "1   418598  친구라도 될 걸 그랬어  거미 (GUMMY)   R&B/Soul                  벌써 넌 내가 편하니   \n",
       "2   711626           살다가      SG 워너비        발라드                 살아도 사는 게 아니래   \n",
       "3  1500196           내사람      SG 워너비   R&B/Soul  내 가슴속에 사는 사람 내가 그토록 아끼는 사람    \n",
       "4  1854856           라라라      SG 워너비        발라드                  그대는 참 아름다워요   \n",
       "\n",
       "                                   translated_lyrics top_sentiment  \\\n",
       "0  [햇살은 우릴 위해 내리고 , 바람도 서롤 감싸게 했죠 , 우리 웃음속에, 계절은 ...            슬픔   \n",
       "1  [벌써 넌 내가 편하니, 웃으며 인사 할 만큼, 까맣게 나를 잊었니, 네 곁에 있는...            불안   \n",
       "2  [살아도 사는 게 아니래, 너 없는 하늘에, 창 없는 감옥 같아서, 웃어도 웃는 게...            슬픔   \n",
       "3  [내 가슴속에 사는 사람 내가 그토록 아끼는 사람 , 너무 소중해 마음껏 안아보지도...            기쁨   \n",
       "4  [그대는 참 아름다워요, 밤 하늘의 별빛보다 빛나요, 지친 나의 마음을 따뜻하게 감...            기쁨   \n",
       "\n",
       "  second_sentiment  \n",
       "0               기쁨  \n",
       "1               슬픔  \n",
       "2               불안  \n",
       "3               불안  \n",
       "4               슬픔  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(emotions)\n",
    "\n",
    "lyrics_final['감정1_encoded'] = le.transform(lyrics_final['top_sentiment'])\n",
    "lyrics_final['감정2_encoded'] = le.transform(lyrics_final['second_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 소설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수: 79\n",
      "None 포함 여부: 79\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN 개수:\", data['text'].isna().sum())  # NaN 개수 확인\n",
    "print(\"None 포함 여부:\", data['text'].isnull().sum())  # None 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수: 0\n",
      "None 포함 여부: 0\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].fillna(\"\")\n",
    "\n",
    "print(\"NaN 개수:\", data['text'].isna().sum())  # NaN 개수 확인\n",
    "print(\"None 포함 여부:\", data['text'].isnull().sum())  # None 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 title을 가진 데이터에서 100개씩 묶어 그룹화\n",
    "data[\"group\"] = data.groupby(\"title\").cumcount() // 100  # 100개 단위 그룹 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>top_sentiment</th>\n",
       "      <th>second_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>[01범보다 무서운 곶감, 화자를 처음 만나 이야기를 들으러 왔다고 하자 서슴없이 ...</td>\n",
       "      <td>분노</td>\n",
       "      <td>당황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>[&lt;봄꿩은 제 울음에 저 죽는다&gt;, 그 말과 같아서 사램이 잘못 되머넌 하는 말여....</td>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>[그래 그 여자가 쪄서 쌀얼 쪄서 밥얼 했어., “잡수라.”구., 그래 한 때를 몽...</td>\n",
       "      <td>상처</td>\n",
       "      <td>당황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>[그랴. 그래 우리 인제 사춘 찾어간다는 얘기를 족~ 갈쳐중개,, “그러시냐구. 그...</td>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이야기꾼 구연설화</td>\n",
       "      <td>[나와서 인제 그 집 먼지 인저 그, 그, 뭐여 면사무소 있는 디 나와서 인제, 거...</td>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                               text top_sentiment  \\\n",
       "0  이야기꾼 구연설화  [01범보다 무서운 곶감, 화자를 처음 만나 이야기를 들으러 왔다고 하자 서슴없이 ...            분노   \n",
       "1  이야기꾼 구연설화  [<봄꿩은 제 울음에 저 죽는다>, 그 말과 같아서 사램이 잘못 되머넌 하는 말여....            상처   \n",
       "2  이야기꾼 구연설화  [그래 그 여자가 쪄서 쌀얼 쪄서 밥얼 했어., “잡수라.”구., 그래 한 때를 몽...            상처   \n",
       "3  이야기꾼 구연설화  [그랴. 그래 우리 인제 사춘 찾어간다는 얘기를 족~ 갈쳐중개,, “그러시냐구. 그...            상처   \n",
       "4  이야기꾼 구연설화  [나와서 인제 그 집 먼지 인저 그, 그, 뭐여 면사무소 있는 디 나와서 인제, 거...            상처   \n",
       "\n",
       "  second_sentiment  \n",
       "0               당황  \n",
       "1               분노  \n",
       "2               당황  \n",
       "3               분노  \n",
       "4               분노  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.groupby([\"file_id\", \"group\"]).agg({\n",
    "    \"title\": \"first\",  # 대표 file_id\n",
    "    \"text\": list,  # 100개씩 묶음\n",
    "    \"sentiment\": lambda x: get_top_two_sentiments(x)  # 빈도가 높은 2개의 감정 추출\n",
    "}).reset_index()\n",
    "\n",
    "# sentiment에서 두 개의 감정을 각각의 칼럼으로 분리\n",
    "data[['top_sentiment', 'second_sentiment']] = pd.DataFrame(data['sentiment'].tolist(), index=data.index)\n",
    "\n",
    "# 불필요한 sentiment 칼럼 삭제\n",
    "data = data.drop(columns=[\"sentiment\", \"group\", \"file_id\"])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수: 0\n",
      "None 포함 여부: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN 개수:\", data['text'].isna().sum())  # NaN 개수 확인\n",
    "print(\"None 포함 여부:\", data['text'].isnull().sum())  # None 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_sentiment</th>\n",
       "      <th>second_sentiment</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>분노</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>3 | 1 | \"사랑해.\" 멍…… 정말 멍…… 얘가 지금 뭐라는 거야? \"너 지금…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>불안</td>\n",
       "      <td>상처</td>\n",
       "      <td>4 | 5 | 으뜸과 곧음이 시작되었다 끝났다 한다 진실로 이러한 이치를 밝게 안다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>상처</td>\n",
       "      <td>분노</td>\n",
       "      <td>5 | 3 | “그건 그럴 수밖에 없었어요. 해원이가 은밀하게 숨긴 데에는 그만 한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>불안</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>4 | 6 | 그녀는 K와 손을 잡고 오솔길을 따라 오르며 나누었던 옛 이야기에 몰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>불안</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>4 | 1 | \"나중에 신혼여행 갔다 오면 한 번 만나자.\" \"그래.\" \"일……다시...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_sentiment second_sentiment  \\\n",
       "2455            분노               기쁨   \n",
       "6203            불안               상처   \n",
       "315             상처               분노   \n",
       "1934            불안               슬픔   \n",
       "1046            불안               기쁨   \n",
       "\n",
       "                                             input_text  \n",
       "2455  3 | 1 | \"사랑해.\" 멍…… 정말 멍…… 얘가 지금 뭐라는 거야? \"너 지금…...  \n",
       "6203  4 | 5 | 으뜸과 곧음이 시작되었다 끝났다 한다 진실로 이러한 이치를 밝게 안다...  \n",
       "315   5 | 3 | “그건 그럴 수밖에 없었어요. 해원이가 은밀하게 숨긴 데에는 그만 한...  \n",
       "1934  4 | 6 | 그녀는 K와 손을 잡고 오솔길을 따라 오르며 나누었던 옛 이야기에 몰...  \n",
       "1046  4 | 1 | \"나중에 신혼여행 갔다 오면 한 번 만나자.\" \"그래.\" \"일……다시...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'No'를 감정 목록에 추가하여 훈련 데이터에 포함\n",
    "emotions_with_no = list(emotions) + ['No']\n",
    "\n",
    "# LabelEncoder 초기화 후 감정 목록에 'No' 포함하여 학습\n",
    "le = LabelEncoder()\n",
    "le.fit(emotions_with_no)\n",
    "\n",
    "# 감정1과 감정2를 숫자로 변환\n",
    "data['감정1_encoded'] = le.transform(data['top_sentiment'])\n",
    "data['감정2_encoded'] = le.transform(data['second_sentiment'])\n",
    "\n",
    "# 수치형 감정1, 감정2와 텍스트 결합\n",
    "data['input_text'] = data['감정1_encoded'].astype(str) + \" | \" + data['감정2_encoded'].astype(str) + \" | \" + data['text'].astype(str)\n",
    "\n",
    "# 불필요한 문자 제거\n",
    "data['input_text'] = data['input_text'].str.replace(r\"[\\[\\],']\", \"\", regex=True)\n",
    "\n",
    "data[['top_sentiment', 'second_sentiment', 'input_text']].sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8972"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No: 0\n",
      "기쁨: 1\n",
      "당황: 2\n",
      "분노: 3\n",
      "불안: 4\n",
      "상처: 5\n",
      "슬픔: 6\n"
     ]
    }
   ],
   "source": [
    "# 감정별 숫자 매핑 출력\n",
    "for emotion, label in zip(le.classes_, le.transform(le.classes_)):\n",
    "    print(f\"{emotion}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class NovelsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, text_column=\"input_text\", max_length=128):\n",
    "        self.data = data.reset_index(drop=True)  # 인덱스 리셋 (중복 방지)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_column = text_column\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, self.text_column] # input_text 가져오기\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        # labels 생성 (input_ids 복사 및 패딩 토큰을 -100으로 설정)\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "# KOGPT2 모델과 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')\n",
    "\n",
    "# 모델 초기화\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.bos_token_id = tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NovelsDataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results/emotion',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=5e-5,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_novels, eval_novels = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = NovelsDataset(train_novels, tokenizer)\n",
    "eval_dataset = NovelsDataset(eval_novels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer에 데이터셋 전달\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,  # 검증 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([ 9130,   739,   466,  9045,   739,   466, 10063,  7584,  9391, 21182,\n",
      "        12311, 35142, 13875,  9317, 16299, 13568, 18017,  9717, 17631, 11247,\n",
      "        15972,  7621,  7422,  8263,   739,     5, 23775, 47711, 10063,  7669,\n",
      "         7445, 11001, 22580, 26309,  7185,  9135, 13115,   406,   377,  9546,\n",
      "         7407, 32552,  9069,  7560,  8159, 22301,  8024,  9274,  7407,  7543,\n",
      "         8146, 16626, 13872, 10063,  8762, 10072,  9215, 18282,  9215,  9878,\n",
      "        13969,  9261, 19023,  9174,  9179,  9432, 12004,  9825, 12024,  7281,\n",
      "         6883,  9173, 13444, 32987,   377, 10063,  8052,  9055,  8694, 15509,\n",
      "          376,  9174,  9179,  9432, 17104,  8744,  7055,  7652,  6919,  7514,\n",
      "          389, 46651,  6824, 12222, 21832,  9122,  7991,   406, 25758,  9720,\n",
      "         6958,  9237, 22882,   406, 16518, 15518, 39717,  9193, 22882,   406,\n",
      "          377,  9546,  7407, 19902, 18191,  6824, 32738,  8006,  9042,  9313,\n",
      "        44083, 14870,  9064,  7472,  7326,  9016, 10063, 17653])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Labels: tensor([ 9130,   739,   466,  9045,   739,   466, 10063,  7584,  9391, 21182,\n",
      "        12311, 35142, 13875,  9317, 16299, 13568, 18017,  9717, 17631, 11247,\n",
      "        15972,  7621,  7422,  8263,   739,     5, 23775, 47711, 10063,  7669,\n",
      "         7445, 11001, 22580, 26309,  7185,  9135, 13115,   406,   377,  9546,\n",
      "         7407, 32552,  9069,  7560,  8159, 22301,  8024,  9274,  7407,  7543,\n",
      "         8146, 16626, 13872, 10063,  8762, 10072,  9215, 18282,  9215,  9878,\n",
      "        13969,  9261, 19023,  9174,  9179,  9432, 12004,  9825, 12024,  7281,\n",
      "         6883,  9173, 13444, 32987,   377, 10063,  8052,  9055,  8694, 15509,\n",
      "          376,  9174,  9179,  9432, 17104,  8744,  7055,  7652,  6919,  7514,\n",
      "          389, 46651,  6824, 12222, 21832,  9122,  7991,   406, 25758,  9720,\n",
      "         6958,  9237, 22882,   406, 16518, 15518, 39717,  9193, 22882,   406,\n",
      "          377,  9546,  7407, 19902, 18191,  6824, 32738,  8006,  9042,  9313,\n",
      "        44083, 14870,  9064,  7472,  7326,  9016, 10063, 17653])\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(\"Input IDs:\", sample['input_ids'])\n",
    "print(\"Attention Mask:\", sample['attention_mask'])\n",
    "print(\"Labels:\", sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2520' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2520/2520 17:47, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.139200</td>\n",
       "      <td>4.040720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.815300</td>\n",
       "      <td>4.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.551100</td>\n",
       "      <td>4.024973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>4.042984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.123900</td>\n",
       "      <td>4.064175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2520, training_loss=3.593004034435938, metrics={'train_runtime': 1067.9079, 'train_samples_per_second': 37.803, 'train_steps_per_second': 2.36, 'total_flos': 2634868850688000.0, 'train_loss': 3.593004034435938, 'epoch': 4.998761456527124})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이야기 생성 함수\n",
    "def generate_story(lyrics_input):\n",
    "    # 입력 토큰화\n",
    "    input_ids = tokenizer.encode(lyrics_input, return_tensors='pt').to(device)\n",
    "\n",
    "    # 출력 생성\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_new_tokens=150, # 새로 생성할 토큰의 개수를 제한\n",
    "        num_return_sequences=1, \n",
    "        temperature=0.8, \n",
    "        top_k=50, \n",
    "        top_p=0.9, \n",
    "        repetition_penalty=1.2, \n",
    "        do_sample=True  # 샘플링 활성화\n",
    "    )\n",
    "\n",
    "    # 입력 길이 추적\n",
    "    input_length = input_ids.shape[1]\n",
    "\n",
    "    # 생성된 토큰 중 입력 토큰 이후의 부분만 디코딩\n",
    "    generated_tokens = output[0][input_length:]\n",
    "    generated_story = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return generated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "밤양갱\n"
     ]
    }
   ],
   "source": [
    "i = 725\n",
    "print(lyrics_final[\"title\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 | 5 | 떠나는 길에 니가 내게 말했지 ‘너는 바라는 게 너무나 많아 잠깐이라도 널 안 바라보면 머리에 불이 나버린다니까’ 나는 흐르려는 눈물을 참고 하려던 얘길 어렵게 누르고 ‘그래 미안해’라는 한 마디로 너랑 나눈 날들 마무리했었지 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야 떠나는 길에 니가 내게 말했지 ‘너는 바라는 게 너무나 많아’ 아냐 내가 늘 바란 건 하나야 한 개뿐이야 달디단 밤양갱 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야 상다리가 부러지고 둘이서 먹다 하나가 쓰러져버려도 나라는 사람을 몰랐던 넌 떠나가다가 돌아서서 말했지 ‘너는 바라는 게 너무나 많아’ 아냐 내가 늘 바란 건 하나야 한 개뿐이야 달디단 밤양갱\n"
     ]
    }
   ],
   "source": [
    "lyrics = \" \".join(lyrics_final[\"translated_lyrics\"][i])\n",
    "\n",
    "prompt = lyrics_final['감정1_encoded'][i].astype(str) + \" | \" + lyrics_final['감정2_encoded'][i].astype(str) + \" | \" + lyrics\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 이야기: 이 다람쥐처럼 그 사람이 내 곁에 머물러 있었어. 하지만 시간이 흘러 이제 내 곁을 떠난다는 걸 모르고 흘려 보낸 날들이 후회하는 날들을 한탄하며 이대로 그리움에 허탈한 마음으로 그리워했던 시간만 보내며 아쉬움이 눈물로 잠들어가는 동안 내가 간절함을 달그락거리지 못해 안타까워하는 걸 어찌할 뿐.... “니 너는 내게 그런 애틋함이나 절망을 참을 담아두고 나를 위해 네 가슴속히 간직하리라 할 수놓는구나~ 하고 속절없이 기다릴 줄 알면 나도 모르게 해놓고 갈망나니 울어버림 같은 마음을 채워다오.” 하며 너를 기다리는 동안 나의 사랑하더니 이제 남은 이야기들은 이제 잊고 싶어서 슬프게 해놓았\n"
     ]
    }
   ],
   "source": [
    "# 가사로 이야기 생성\n",
    "generated_story = generate_story(prompt)\n",
    "print(\"생성된 이야기:\", generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 이야기: 인지 이젠데 왜 내가 좋아하는지 그래 속상하기만 말예 퇴근거리는 게 참으론 정말이지 남이 나를 버리고 지금이 딱히 한숨 쉬었는지 알면서.... 이러면 금방엔 숨소리 질러 가며 소리 죽여 버릇한 기분이 좋아서 그냥 그러는 거냐? 이제 더러운 세상 물끄떡하고 예사로운 걸어서 그런 건가 못해~ 하고 사는데. 그만 이렇게 예쁜 척하는 소리가 나랑말루 오죽 나래 그래 가지 않고 그저 눈 감고 삐딱다리 놓으면 살그렁거니 이마에 이어두 못 하게 할까 봐놓고 사는 저러다 말고 다리 뻗고 가만히 들여다보면 예뻐한다ᆞ오래야 제자리 앉으며 맘\n"
     ]
    }
   ],
   "source": [
    "# 가사로 이야기 생성\n",
    "# lyrics_input = \"\"\n",
    "# generated_story = generate_story(lyrics_input, tag1=\"2\", tag2=\"2\")\n",
    "# print(\"생성된 이야기:\", generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lyrics_final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslated_lyrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][i])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 가사로 이야기 생성\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m generated_story \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_story\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n\u001b[0;32m     14\u001b[0m generated_stories\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: title, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_story\u001b[39m\u001b[38;5;124m\"\u001b[39m: generated_story})\n",
      "Cell \u001b[1;32mIn[69], line 7\u001b[0m, in \u001b[0;36mgenerate_story\u001b[1;34m(lyrics_input)\u001b[0m\n\u001b[0;32m      4\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(lyrics_input, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 출력 생성\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 새로 생성할 토큰의 개수를 제한\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 샘플링 활성화\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 입력 길이 추적\u001b[39;00m\n\u001b[0;32m     19\u001b[0m input_length \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\generation\\utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2252\u001b[0m     )\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2256\u001b[0m         input_ids,\n\u001b[0;32m   2257\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2258\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2259\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2260\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2261\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2262\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2263\u001b[0m     )\n\u001b[0;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2275\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\generation\\utils.py:3257\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3255\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3259\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3260\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3261\u001b[0m     outputs,\n\u001b[0;32m   3262\u001b[0m     model_kwargs,\n\u001b[0;32m   3263\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3264\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1062\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1062\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1077\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:829\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    827\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _use_sdpa:\n\u001b[1;32m--> 829\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_causal_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:378\u001b[0m, in \u001b[0;36m_prepare_4d_causal_attention_mask_for_sdpa\u001b[1;34m(attention_mask, input_shape, inputs_embeds, past_key_values_length, sliding_window)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture the controlflow `is_causal=attention_mask is None and q_len > 1`\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# used as an SDPA argument. We keep compatibility with these tracing tools by always using SDPA's `attn_mask` argument in case we are tracing.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).\u001b[39;00m\n\u001b[0;32m    376\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs_embeds, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy) \u001b[38;5;129;01mor\u001b[39;00m is_torchdynamo_compiling()\n\u001b[1;32m--> 378\u001b[0m ignore_causal_mask \u001b[38;5;241m=\u001b[39m \u001b[43mAttentionMaskConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ignore_causal_mask_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_causal_mask:\n\u001b[0;32m    386\u001b[0m     expanded_4d_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:288\u001b[0m, in \u001b[0;36mAttentionMaskConverter._ignore_causal_mask_sdpa\u001b[1;34m(attention_mask, inputs_embeds, past_key_values_length, sliding_window, is_training)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(attention_mask\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(attention_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key_value_length \u001b[38;5;241m==\u001b[39m query_length:\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;66;03m# For query_length == 1, causal attention and bi-directional attention are the same.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m         ignore_causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 생성된 이야기들을 저장할 리스트\n",
    "generated_stories = []\n",
    "\n",
    "# 701부터 750까지 반복하여 가사로 이야기 생성\n",
    "for i in range(701, 751):\n",
    "    # 각 가사 제목과 번역된 가사 추출\n",
    "    title = lyrics_final[\"title\"][i]\n",
    "    prompt = \" \".join(lyrics_final[\"translated_lyrics\"][i])\n",
    "\n",
    "    # 가사로 이야기 생성\n",
    "    generated_story = generate_story(prompt)\n",
    "\n",
    "    # 결과 저장\n",
    "    generated_stories.append({\"title\": title, \"generated_story\": generated_story})\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "df = pd.DataFrame(generated_stories)\n",
    "\n",
    "# CSV로 저장\n",
    "df.to_csv(\"emotion-tagged-generated_stories.csv\", index=False)\n",
    "\n",
    "print(\"csv 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
