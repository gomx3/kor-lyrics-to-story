{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 데이터\n",
    "data = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"content\": \"파란 하늘 아래에서 사랑하는 사람들과 함께 손을 잡고, 웃음이 넘쳐나는 순간들. 모든 게 완벽하게 맞아떨어지는 이 순간, 나의 마음은 행복으로 가득 차 있다. 내 마음 속에서 기쁨이 춤추고 있다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"content\": \"오늘 너무 행복해서 날아갈 것만 같고 너무 기쁘고 기쁘고 기쁘고 정말 기쁘다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"content\": \"햇살 가득한 정원에서 친구들과 웃으며 피크닉을 즐기고 있어요. 모든 걱정을 잊고, 그냥 지금 이 순간에만 집중하는 기분이에요. 행복이 내 몸속 깊숙이 퍼지고 있어요!\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"content\": \"산길을 걷던 남자는 우연히 떨어진 그림엽서를 발견했다. 그림 속에는 자신이 어릴 적 갔던 바다가 그려져 있었다. 뒷면에는 낯익은 필체로 '다시 만나자'라는 문구가 적혀 있었다. 누군가의 초대 같았다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"content\": \"한밤중에 잠에서 깬 소년은 창문 밖에서 들려오는 이상한 소리를 들었다. 밖을 내다보니 작은 고양이가 소리 내어 울고 있었다. 소년은 고양이를 집 안으로 데려왔고, 그날 이후 둘은 떨어질 수 없는 친구가 되었다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"content\": \"강가에서 낚시를 하던 노인은 물속에서 빛나는 병을 발견했다. 병 속에는 오래된 쪽지가 들어 있었는데, '이 병을 발견한 이는 행운을 얻을 것이다'라고 적혀 있었다. 그날부터 노인의 삶은 놀랍도록 변하기 시작했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"content\": \"비 오는 날, 한 소녀는 학교로 가는 길에 낡은 우산을 발견했다. 우산에는 '행운의 우산'이라는 작은 메모가 붙어 있었다. 소녀는 우산을 쓰기 시작했고, 이상하게도 그날 이후 좋은 일이 계속해서 일어났다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"content\": \"숲속 깊은 곳에 있는 작은 오두막에는 매일 밤 불빛이 켜졌다. 마을 사람들은 그곳에 누군가가 산다는 소문을 들었지만, 아무도 그를 본 적이 없었다. 어느 날, 용기를 낸 한 소년이 오두막을 찾아갔고 놀라운 비밀을 발견했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 9,\n",
    "        \"content\": \"늦은 밤, 정류장에서 버스를 기다리던 남자는 이상한 기운을 느꼈다. 누군가 자신을 지켜보는 것 같았다. 고개를 돌리자, 낡은 벤치 위에 오래된 사진이 놓여 있었다. 사진 속에는 그와 똑같이 생긴 사람이 서 있었다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 10,\n",
    "        \"content\": \"한적한 해변에서 발견된 오래된 일기장은 누군가의 비밀로 가득 차 있었다. 글을 읽던 소녀는 일기 속 주인공과 자신의 삶이 이상하리만큼 닮아 있다는 것을 알게 되었다. 마치 자신을 위한 이야기처럼 느껴졌다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 11,\n",
    "        \"content\": \"노을이 지는 강가에서 한 남자가 낚시를 하고 있었다. 물속에서 무언가 빛나는 것을 발견한 그는 손을 뻗어 그것을 꺼냈다. 그것은 오래된 황금 반지였다. 반지에는 '영원한 사랑'이라는 글자가 새겨져 있었고, 그 후로 그의 삶은 놀라운 방향으로 흘러갔다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 12,\n",
    "        \"content\": \"작은 도서관의 구석에서 낡은 책 한 권이 발견되었다. 책의 첫 페이지에는 '읽는 이에게 행운을'이라는 문구가 적혀 있었다. 책을 읽기 시작한 소녀는 매일 꿈속에서 책 속의 이야기를 경험하며 놀라운 모험을 시작했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 13,\n",
    "        \"content\": \"도시의 오래된 골목길에는 늘 기타를 치는 한 소년이 있었다. 그는 누구도 모르는 곡을 연주했지만, 그 음악은 지나가는 사람들의 마음을 울렸다. 어느 날, 한 청중이 다가와 '이 곡은 어디서 배운 거니?'라고 묻자 소년은 '꿈에서 들었다'고 답했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 14,\n",
    "        \"content\": \"버려진 놀이터에서 놀던 아이들은 지하에 숨겨진 비밀 문을 발견했다. 문을 열자 거대한 미로가 나타났고, 아이들은 미로 속에서 환상적인 모험을 시작했다. 그곳에는 꿈에서만 보던 동물들과 마법의 세계가 기다리고 있었다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 15,\n",
    "        \"content\": \"작은 카페의 메뉴판 뒤에는 오래된 편지가 숨겨져 있었다. 한 여성이 우연히 발견한 편지에는 '사랑하는 이에게'라는 제목과 함께 과거의 가슴 절절한 이야기가 담겨 있었다. 그녀는 편지의 주인을 찾아 나섰고, 놀라운 인연을 만나게 되었다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 16,\n",
    "        \"content\": \"학교 뒷마당에서 놀던 소년은 땅에 묻힌 작은 상자를 발견했다. 상자 속에는 오래된 동전과 함께 '용기를 가지면 모든 것을 얻을 수 있다'는 글귀가 적힌 쪽지가 있었다. 소년은 이후 도전하는 삶을 살며 꿈을 이루기 시작했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 17,\n",
    "        \"content\": \"한밤중에 잠에서 깬 한 남자는 창밖에 빛나는 별 하나가 점점 커지는 것을 보았다. 별은 그의 방으로 들어와 작은 구슬이 되었고, 구슬은 그에게 소원을 들어줄 수 있다고 말했다. 그는 인생의 가장 중요한 소원을 빌기로 결심했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 18,\n",
    "        \"content\": \"낯선 도시의 오래된 다리 위에서 한 소녀가 사진을 찍고 있었다. 사진 속에 나타난 희미한 그림자는 그녀가 잃어버린 친구를 닮아 있었다. 소녀는 진실을 찾기 위해 다리 아래 숨겨진 비밀을 조사하기 시작했다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 19,\n",
    "        \"content\": \"가을의 어느 날, 낡은 나무 아래에서 한 청년이 오래된 손수건을 발견했다. 손수건에는 정성스럽게 수놓아진 이니셜과 함께 '기억의 조각'이라는 글자가 새겨져 있었다. 그는 손수건의 주인을 찾기 위해 여정을 떠났다.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 20,\n",
    "        \"content\": \"한 마을에는 전설이 있었다. 마을 중앙의 큰 나무에 걸린 종을 울리면 소원을 이룰 수 있다는 것이다. 어느 날, 한 아이가 용기를 내어 종을 울렸다. 하지만 종소리와 함께 나타난 것은 소원이 아닌 마을의 오래된 비밀이었다.\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드\n",
    "train = pd.read_csv('../datasets/sentiment_conversation/train.csv')\n",
    "val = pd.read_csv('../datasets/sentiment_conversation/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4    26301\n",
      "2    26000\n",
      "3    25957\n",
      "1    25814\n",
      "5    24936\n",
      "0    16947\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          2                          일은 왜 해도 해도 끝이 없을까? 화가 난다.\n",
      "1          2     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.\n",
      "2          2  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...\n",
      "3          2  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...\n",
      "4          2              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.\n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          4  이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...\n",
      "1          4              회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.\n",
      "2          4                      상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워.\n",
      "3          4          이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.\n",
      "4          4                       직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼.\n"
     ]
    }
   ],
   "source": [
    "print(val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/klue/roberta-base/resolve/main/vocab.txt from cache at C:\\Users\\kimso/.cache\\huggingface\\transformers\\e8441a174492958462b6b16b6db8f1e7253cd149ca779522cadd812d55091b89.d1b86bed49516351c7bb29b19d7e7be2ab53b931bcb1f9b2aacfb71f2124d25a\n",
      "loading file https://huggingface.co/klue/roberta-base/resolve/main/tokenizer.json from cache at C:\\Users\\kimso/.cache\\huggingface\\transformers\\233a5b2c17873a8477b62dd92a02092a9937759e924a5f22b111becebb8aba5e.44c30ade4958fcfd446e66025e10a5b380cdd0bbe9b3fb7a794f357e7f0f34c2\n",
      "loading file https://huggingface.co/klue/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/klue/roberta-base/resolve/main/special_tokens_map.json from cache at C:\\Users\\kimso/.cache\\huggingface\\transformers\\9d0c87e44b00acfbfbae931b2e4068eb6311a0c3e71e23e5400bdf57cab4bfbf.70c17d6e4d492c8f24f5bb97ab56c7f272e947112c6faf9dd846da42ba13eb23\n",
      "loading file https://huggingface.co/klue/roberta-base/resolve/main/tokenizer_config.json from cache at C:\\Users\\kimso/.cache\\huggingface\\transformers\\9a9f77abeddd1bbd8de28608e78dd3604287ad91abd4796cd25ad936715b7640.5b0ba083b234382bb4c99ee0c9f4fca4cadaa053dd17c32dabfe0de2f629af1f\n"
     ]
    }
   ],
   "source": [
    "# 2. KLUE/roberta-base 토크나이저 적용\n",
    "model_name = \"klue/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 360/91230 [07:23<31:05:32,  1.23s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Map:  49%|████▉     | 72000/145955 [00:03<00:04, 18204.69 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(train)\n\u001b[0;32m      3\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(val)\n\u001b[1;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mremove_columns([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\datasets\\arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3055\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3056\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3057\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\datasets\\arrow_dataset.py:3458\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3454\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3455\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3456\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3458\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3462\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3467\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\datasets\\arrow_dataset.py:3320\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3319\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3320\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3322\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3323\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3324\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m, in \u001b[0;36mtokenize_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(examples):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2310\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2306\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2307\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2308\u001b[0m         )\n\u001b[0;32m   2309\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2312\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2331\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2332\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2348\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2349\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2495\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2486\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2487\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2488\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2492\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2493\u001b[0m )\n\u001b[1;32m-> 2495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:385\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    378\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    379\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    383\u001b[0m )\n\u001b[1;32m--> 385\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    397\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[0;32m    399\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[0;32m    409\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. Hugging Face Dataset 변환\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\"])\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "val_dataset.set_format(\"torch\")\n",
    "\n",
    "# 추가\n",
    "small_train_dataset = train_dataset.select(range(100))  # 100개만 학습\n",
    "small_val_dataset = val_dataset.select(range(20))  # 20개만 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/roberta-base/resolve/main/config.json from cache at C:\\Users\\kimso/.cache\\huggingface\\transformers\\a96469ca2a238496d435a0e9e202f261119c146a0326444b6d68ae1adc35e04f.85b0b02ba2a483f3adb8a60ab70dbd875768fcd5e6cdb21a593c6e02fdffac3a\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/roberta-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\kimso/.cache\\huggingface\\transformers\\b204e0dc0a3b8fd45b35e7fcefd97c5f839b86c14aea510f1eb38fb8469e23d8.57d3cd0dfa80e5a249a776870dc87b6da993900685a271086750174009115320\n",
      "c:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\modeling_utils.py:1211: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 모델 정의\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(train[\"sentiment\"].unique()))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# 5. TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 145955\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27369\n",
      "                                                     \n",
      "  0%|          | 360/91230 [02:39<4:25:02,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7838, 'learning_rate': 4.908655778435456e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \u001b[A\n",
      "  0%|          | 360/91230 [04:07<4:25:02,  5.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7939, 'learning_rate': 4.8173115568709124e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  0%|          | 360/91230 [05:35<4:25:02,  5.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7907, 'learning_rate': 4.7259673353063685e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 6. Trainer 정의 및 학습\u001b[39;00m\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      4\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m      5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m      6\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\trainer.py:1315\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m scale_before \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m scale_after\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed:\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:130\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    129\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\optimization.py:358\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    355\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    356\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m step_size \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2) \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[1;32m--> 358\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# Just adding the square of the weights to the loss function is *not*\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# the correct way of using L2 regularization/weight decay with Adam,\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# since that will interact with the m and v parameters in strange ways.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# of the weights to the loss with plain (non-momentum) SGD.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# Add weight decay at the end (fixed version)\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Trainer 정의 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,  # 소규모 데이터셋 사용\n",
    "    eval_dataset=small_val_dataset,  # 소규모 검증 데이터 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 파란 하늘 아래에서 사랑하는 사람들과 함께 손을 잡고, 웃음이 넘쳐나는 순간들. 모든 게 완벽하게 맞아떨어지는 이 순간, 나의 마음은 행복으로 가득 차 있다. 내 마음 속에서 기쁨이 춤추고 있다.\n",
      "Scores: [[0.20696835219860077, 0.16610361635684967, 0.17177818715572357, 0.1654752939939499, 0.1356823444366455, 0.1539921909570694]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 오늘 너무 행복해서 날아갈 것만 같고 너무 기쁘고 기쁘고 기쁘고 정말 기쁘다.\n",
      "Scores: [[0.210343137383461, 0.16448689997196198, 0.16351763904094696, 0.16429173946380615, 0.14139224588871002, 0.1559683233499527]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 햇살 가득한 정원에서 친구들과 웃으며 피크닉을 즐기고 있어요. 모든 걱정을 잊고, 그냥 지금 이 순간에만 집중하는 기분이에요. 행복이 내 몸속 깊숙이 퍼지고 있어요!\n",
      "Scores: [[0.2131807953119278, 0.16164669394493103, 0.1680438071489334, 0.16505427658557892, 0.1355336606502533, 0.15654070675373077]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 산길을 걷던 남자는 우연히 떨어진 그림엽서를 발견했다. 그림 속에는 자신이 어릴 적 갔던 바다가 그려져 있었다. 뒷면에는 낯익은 필체로 '다시 만나자'라는 문구가 적혀 있었다. 누군가의 초대 같았다.\n",
      "Scores: [[0.2065226286649704, 0.16660113632678986, 0.16835784912109375, 0.16338993608951569, 0.13892100751399994, 0.15620744228363037]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한밤중에 잠에서 깬 소년은 창문 밖에서 들려오는 이상한 소리를 들었다. 밖을 내다보니 작은 고양이가 소리 내어 울고 있었다. 소년은 고양이를 집 안으로 데려왔고, 그날 이후 둘은 떨어질 수 없는 친구가 되었다.\n",
      "Scores: [[0.20787517726421356, 0.16500847041606903, 0.16653184592723846, 0.16314633190631866, 0.13950930535793304, 0.15792888402938843]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 강가에서 낚시를 하던 노인은 물속에서 빛나는 병을 발견했다. 병 속에는 오래된 쪽지가 들어 있었는데, '이 병을 발견한 이는 행운을 얻을 것이다'라고 적혀 있었다. 그날부터 노인의 삶은 놀랍도록 변하기 시작했다.\n",
      "Scores: [[0.20740027725696564, 0.16698576509952545, 0.16693146526813507, 0.16370584070682526, 0.1385641247034073, 0.15641255676746368]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 비 오는 날, 한 소녀는 학교로 가는 길에 낡은 우산을 발견했다. 우산에는 '행운의 우산'이라는 작은 메모가 붙어 있었다. 소녀는 우산을 쓰기 시작했고, 이상하게도 그날 이후 좋은 일이 계속해서 일어났다.\n",
      "Scores: [[0.20846346020698547, 0.16540808975696564, 0.16699649393558502, 0.1633162945508957, 0.13887269794940948, 0.15694297850131989]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 숲속 깊은 곳에 있는 작은 오두막에는 매일 밤 불빛이 켜졌다. 마을 사람들은 그곳에 누군가가 산다는 소문을 들었지만, 아무도 그를 본 적이 없었다. 어느 날, 용기를 낸 한 소년이 오두막을 찾아갔고 놀라운 비밀을 발견했다.\n",
      "Scores: [[0.2082592248916626, 0.16491663455963135, 0.16769003868103027, 0.1628206968307495, 0.1369752585887909, 0.15933820605278015]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 늦은 밤, 정류장에서 버스를 기다리던 남자는 이상한 기운을 느꼈다. 누군가 자신을 지켜보는 것 같았다. 고개를 돌리자, 낡은 벤치 위에 오래된 사진이 놓여 있었다. 사진 속에는 그와 똑같이 생긴 사람이 서 있었다.\n",
      "Scores: [[0.20616747438907623, 0.16426071524620056, 0.16916410624980927, 0.16208237409591675, 0.1405373215675354, 0.15778790414333344]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한적한 해변에서 발견된 오래된 일기장은 누군가의 비밀로 가득 차 있었다. 글을 읽던 소녀는 일기 속 주인공과 자신의 삶이 이상하리만큼 닮아 있다는 것을 알게 되었다. 마치 자신을 위한 이야기처럼 느껴졌다.\n",
      "Scores: [[0.20677243173122406, 0.1641581952571869, 0.16707752645015717, 0.16409224271774292, 0.13856817781925201, 0.15933142602443695]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 노을이 지는 강가에서 한 남자가 낚시를 하고 있었다. 물속에서 무언가 빛나는 것을 발견한 그는 손을 뻗어 그것을 꺼냈다. 그것은 오래된 황금 반지였다. 반지에는 '영원한 사랑'이라는 글자가 새겨져 있었고, 그 후로 그의 삶은 놀라운 방향으로 흘러갔다.\n",
      "Scores: [[0.20648860931396484, 0.1663895547389984, 0.16667988896369934, 0.16412054002285004, 0.13860361278057098, 0.1577177345752716]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 작은 도서관의 구석에서 낡은 책 한 권이 발견되었다. 책의 첫 페이지에는 '읽는 이에게 행운을'이라는 문구가 적혀 있었다. 책을 읽기 시작한 소녀는 매일 꿈속에서 책 속의 이야기를 경험하며 놀라운 모험을 시작했다.\n",
      "Scores: [[0.2104940265417099, 0.16452008485794067, 0.16726054251194, 0.16212716698646545, 0.1383802443742752, 0.15721793472766876]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도시의 오래된 골목길에는 늘 기타를 치는 한 소년이 있었다. 그는 누구도 모르는 곡을 연주했지만, 그 음악은 지나가는 사람들의 마음을 울렸다. 어느 날, 한 청중이 다가와 '이 곡은 어디서 배운 거니?'라고 묻자 소년은 '꿈에서 들었다'고 답했다.\n",
      "Scores: [[0.20784805715084076, 0.16453056037425995, 0.16988739371299744, 0.16141948103904724, 0.1376260221004486, 0.1586885005235672]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 버려진 놀이터에서 놀던 아이들은 지하에 숨겨진 비밀 문을 발견했다. 문을 열자 거대한 미로가 나타났고, 아이들은 미로 속에서 환상적인 모험을 시작했다. 그곳에는 꿈에서만 보던 동물들과 마법의 세계가 기다리고 있었다.\n",
      "Scores: [[0.2059413641691208, 0.16396352648735046, 0.16522569954395294, 0.1650048941373825, 0.1405322253704071, 0.15933232009410858]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 작은 카페의 메뉴판 뒤에는 오래된 편지가 숨겨져 있었다. 한 여성이 우연히 발견한 편지에는 '사랑하는 이에게'라는 제목과 함께 과거의 가슴 절절한 이야기가 담겨 있었다. 그녀는 편지의 주인을 찾아 나섰고, 놀라운 인연을 만나게 되었다.\n",
      "Scores: [[0.20776408910751343, 0.1662059724330902, 0.16663283109664917, 0.16296416521072388, 0.1378200501203537, 0.15861287713050842]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 학교 뒷마당에서 놀던 소년은 땅에 묻힌 작은 상자를 발견했다. 상자 속에는 오래된 동전과 함께 '용기를 가지면 모든 것을 얻을 수 있다'는 글귀가 적힌 쪽지가 있었다. 소년은 이후 도전하는 삶을 살며 꿈을 이루기 시작했다.\n",
      "Scores: [[0.2098192721605301, 0.1648184061050415, 0.16668465733528137, 0.16430401802062988, 0.1385207623243332, 0.15585289895534515]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한밤중에 잠에서 깬 한 남자는 창밖에 빛나는 별 하나가 점점 커지는 것을 보았다. 별은 그의 방으로 들어와 작은 구슬이 되었고, 구슬은 그에게 소원을 들어줄 수 있다고 말했다. 그는 인생의 가장 중요한 소원을 빌기로 결심했다.\n",
      "Scores: [[0.20931857824325562, 0.1661340296268463, 0.16584573686122894, 0.1646013706922531, 0.13792413473129272, 0.1561761498451233]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 낯선 도시의 오래된 다리 위에서 한 소녀가 사진을 찍고 있었다. 사진 속에 나타난 희미한 그림자는 그녀가 잃어버린 친구를 닮아 있었다. 소녀는 진실을 찾기 위해 다리 아래 숨겨진 비밀을 조사하기 시작했다.\n",
      "Scores: [[0.20668038725852966, 0.165244460105896, 0.16751642525196075, 0.16386492550373077, 0.1369621455669403, 0.15973159670829773]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 가을의 어느 날, 낡은 나무 아래에서 한 청년이 오래된 손수건을 발견했다. 손수건에는 정성스럽게 수놓아진 이니셜과 함께 '기억의 조각'이라는 글자가 새겨져 있었다. 그는 손수건의 주인을 찾기 위해 여정을 떠났다.\n",
      "Scores: [[0.2043720930814743, 0.16696244478225708, 0.1710442304611206, 0.16396695375442505, 0.138080894947052, 0.15557342767715454]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한 마을에는 전설이 있었다. 마을 중앙의 큰 나무에 걸린 종을 울리면 소원을 이룰 수 있다는 것이다. 어느 날, 한 아이가 용기를 내어 종을 울렸다. 하지만 종소리와 함께 나타난 것은 소원이 아닌 마을의 오래된 비밀이었다.\n",
      "Scores: [[0.2082587033510208, 0.16583797335624695, 0.16709835827350616, 0.16404102742671967, 0.13607627153396606, 0.15868765115737915]]\n",
      "Predicted label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    inputs = tokenizer(item['content'], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores = torch.softmax(outputs.logits, dim=1)  # 감성 확률 계산\n",
    "        predicted_label = torch.argmax(scores, dim=1).item()\n",
    "\n",
    "    print(f\"Text: {item['content']}\")\n",
    "    print(f\"Scores: {scores.tolist()}\")\n",
    "    print(f\"Predicted label: {predicted_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "output_file = './results/using_test_data.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as json_f:\n",
    "    json.dump(data, json_f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
